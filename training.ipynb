{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: import"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "from _MatchNotFoundException import MatchNotFoundException"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "match_cols = ['season', 'round'] + \\\n",
    "['date', 'time', 'referee', 'home_team', 'away_team', 'home_score', 'away_score'] + \\\n",
    "['home_coach'] + \\\n",
    "['home_player_' + str(i) for i in range(1, 12)] + \\\n",
    "['home_substitute_' + str(i) for i in range(1, 13)] + \\\n",
    "['away_coach'] + \\\n",
    "['away_player_' + str(i) for i in range(1, 12)] + \\\n",
    "['away_substitute_' + str(i) for i in range(1, 13)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "tot_num_of_feats = len(train.columns)\n",
    "del train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: dataset definition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# utility methods\n",
    "def get_match_by_team_season_round(df: pd.DataFrame, team: str, season: int, round: int) -> pd.DataFrame:\n",
    "    \"\"\"Get the match played by the given team in the given season and round. If the team has not played any match in that round, an empty dataframe is returned.\"\"\"\n",
    "    return df[((df[f'home_team_{team}'] == 1) | (df[f'away_team_{team}'] == 1)) & (df['round'] == round) & (df['season'] == season)]\n",
    "\n",
    "\n",
    "def get_last_n_matches_played_by_team_before_round_in_season(df: pd.DataFrame, team: str, season: int, round: int, n: int) -> pd.DataFrame:\n",
    "    \"\"\"Look in df for the last n matches played by the given team before the given round and season. A dataframe with exactly n element is returned.\n",
    "    If n matches can't be found from the current season, the previous ones are iteratively considered, until n matches are found or the end\n",
    "    of the dataframe is reached, in which case padding is applied to ensure a result size of n.\"\"\"\n",
    "\n",
    "    def exists_historical_matches_before_round_and_season(q_round: int, q_season: int) -> bool:\n",
    "        if (q_season == 0) & (q_round <= 1):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def decrement_round_in_season(c_round: int, c_season: int) -> (int, int):\n",
    "        if c_round - 1 > 0:\n",
    "            c_round -= 1\n",
    "            return c_round, c_season\n",
    "        c_season -= 1\n",
    "        c_round = 38\n",
    "        return c_round, c_season\n",
    "\n",
    "    current_round, current_season = round, season\n",
    "    result = pd.DataFrame()\n",
    "    while True:\n",
    "        if not exists_historical_matches_before_round_and_season(current_round, current_season):\n",
    "            if result.empty:\n",
    "                raise MatchNotFoundException\n",
    "            return fill_with_padding(result)\n",
    "        current_round, current_season = decrement_round_in_season(current_round, current_season)\n",
    "        historical_match_at_current_round = get_match_by_team_season_round(df, team, current_season, current_round)\n",
    "        if not historical_match_at_current_round.empty:\n",
    "            result = pd.concat([result, historical_match_at_current_round])\n",
    "            if len(result) == n:\n",
    "                return result\n",
    "\n",
    "\n",
    "def fill_with_padding(source: pd.DataFrame):\n",
    "    if len(source) < 5:\n",
    "        padding = source.tail(1)\n",
    "        for i in range(5 - len(source)):\n",
    "            source = pd.concat([source, padding], ignore_index=True)\n",
    "    return source\n",
    "\n",
    "\n",
    "def get_playing_home_team_name(row: pd.DataFrame) -> str:\n",
    "    team_columns = row.loc[:, [col for col in row.columns if col.startswith('home_team_')]]\n",
    "    team_name = team_columns.where(team_columns == 1).dropna(axis=1).columns[0].replace('home_team_', '')\n",
    "    return team_name\n",
    "\n",
    "\n",
    "def get_playing_away_team_name(row: pd.DataFrame) -> str:\n",
    "    team_columns = row.loc[:, [col for col in row.columns if col.startswith('away_team_')]]\n",
    "    team_name = team_columns.where(team_columns == 1).dropna(axis=1).columns[0].replace('away_team_', '')\n",
    "    return team_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class SerieAFootballMatchesDataset(Dataset):\n",
    "    def __init__(self, csv_file, history_len = 5):\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        self.history_len = history_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        def show_error(index, error_x, error_x_historical_home, error_x_historical_away, error_y):\n",
    "            print(f'error at index (scaled): {index} (unscaled): {self.unscale_min_idx(index)}')\n",
    "            print(f'x: {error_x}')\n",
    "            print(f'x.shape: {error_x.shape}')\n",
    "            print(f'x_historical_home: {error_x_historical_home}')\n",
    "            print(f'x_historical_home.shape: {error_x_historical_home.shape}')\n",
    "            print(f'x_historical_away: {error_x_historical_away}')\n",
    "            print(f'x_historical_away.shape: {error_x_historical_away.shape}')\n",
    "            print(f'y: {error_y}')\n",
    "            print(f'y.shape: {error_y.shape}')\n",
    "\n",
    "        idx = self.scale_min_idx(idx)\n",
    "        x = self.dataframe.iloc[[idx]]  # df\n",
    "        y = self.dataframe[['result_home', 'result_draw', 'result_away']].iloc[0].values\n",
    "        try: # if we are not able to fetch at least one historical match, then we switch to another index\n",
    "            last_n_games_home, last_n_games_away = self.retrieve_historical_data(x)\n",
    "            x, x_historical_home, x_historical_away, y = self.to_tensor(x, last_n_games_home, last_n_games_away, y)\n",
    "            exp_num_of_features = len(self.dataframe.columns)\n",
    "            if x.shape[0] != exp_num_of_features:\n",
    "                show_error(idx, x, x_historical_home, x_historical_away, y)\n",
    "            if (x_historical_home.shape[0] != 5) | (x_historical_home.shape[1] != exp_num_of_features):\n",
    "                show_error(idx, x, x_historical_home, x_historical_away, y)\n",
    "            if (x_historical_away.shape[0] != 5) | (x_historical_away.shape[1] != exp_num_of_features):\n",
    "                show_error(idx, x, x_historical_home, x_historical_away, y)\n",
    "            if y.shape[0] != 3:\n",
    "                show_error(idx, x, x_historical_home, x_historical_away, y)\n",
    "            return x, x_historical_home, x_historical_away, y\n",
    "        except MatchNotFoundException:\n",
    "            new_idx = randrange(0, len(self.dataframe))\n",
    "            print(f'MatchNotFoundException for idx={idx}, switching to idx={new_idx}')\n",
    "            return self.__getitem__(new_idx)\n",
    "\n",
    "    def scale_min_idx(self, idx: int) -> int:\n",
    "        \"\"\"Scale the given index to a range with a new minimum that allows for historical data retrieval\"\"\"\n",
    "        old_min = 0\n",
    "        old_max = len(self.dataframe)\n",
    "        # idx = 10 corresponds to the first match of the second round.\n",
    "        # This ensure the retrieval of at least 1 historical match.\n",
    "        # In the worst case scenario, padding will fill the other 4 historical slots.\n",
    "        new_min = 10\n",
    "        new_max = old_max\n",
    "        return self.scale_idx(idx, old_min, old_max, new_min, new_max)\n",
    "\n",
    "    def unscale_min_idx(self, idx: int) -> int:\n",
    "        \"\"\"Apply the inverse transformation of scale_min_idx\"\"\"\n",
    "        old_min = 10\n",
    "        old_max = len(self.dataframe)\n",
    "        new_min = 0\n",
    "        new_max = old_max\n",
    "        return self.scale_idx(idx, old_min, old_max, new_min, new_max)\n",
    "\n",
    "    def scale_idx(self, idx, old_min, old_max, new_min, new_max):\n",
    "        \"\"\"Scale the given index to a new range\"\"\"\n",
    "        old_range = old_max - old_min\n",
    "        new_range = new_max - new_min\n",
    "        normalized_idx = (idx - old_min) / old_range\n",
    "        return int(round(normalized_idx * new_range + new_min))\n",
    "\n",
    "    def retrieve_historical_data(self, source: pd.DataFrame):\n",
    "        \"\"\"Retrieve historical data for home and away teams from source\"\"\"\n",
    "        last_n_games_home = get_last_n_matches_played_by_team_before_round_in_season(\n",
    "            self.dataframe, get_playing_home_team_name(source), source['season'].values[0], source['round'].values[0], self.history_len)\n",
    "        last_n_games_away = get_last_n_matches_played_by_team_before_round_in_season(\n",
    "            self.dataframe, get_playing_away_team_name(source), source['season'].values[0], source['round'].values[0], self.history_len)\n",
    "        return last_n_games_home, last_n_games_away\n",
    "\n",
    "    def to_tensor(self, x: pd.DataFrame, x_historical_home: pd.DataFrame, x_historical_away: pd.DataFrame, y: list[int]):\n",
    "        x_tensor = torch.flatten(torch.tensor(x.values))\n",
    "        x_historical_home_tensor = torch.tensor(x_historical_home.values)\n",
    "        x_historical_away_tensor = torch.tensor(x_historical_away.values)\n",
    "        y_tensor = torch.tensor(y)\n",
    "        return x_tensor, x_historical_home_tensor, x_historical_away_tensor, y_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "train_dataset = SerieAFootballMatchesDataset(csv_file='train.csv')\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = SerieAFootballMatchesDataset(csv_file='test.csv')\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "num_epochs = 1\n",
    "hidden_size = 128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model definition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat([input, hidden], dim=0)\n",
    "        pre_hidden = self.linear(combined)\n",
    "        hidden = self.tanh(pre_hidden)\n",
    "        return hidden\n",
    "\n",
    "    def init_hidden(self, minibatch_size):\n",
    "        return torch.zeros(minibatch_size, self.hidden_size)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 3),\n",
    "            # nn.Softmax(dim=1) softmax is applied implicitly by CrossEntropyLoss\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 'x' is the combination of: 'x', 'x_historical_home', 'x_historical_away'\n",
    "        # they all have size: minibatch_size x num_of_feats\n",
    "        x = self.flatten(x) # just in case x was not flattened\n",
    "        output = self.layers(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class HybridNetwork(pl.LightningModule):\n",
    "    def __init__(self, rnn_home_model: RNN, rnn_away_model: RNN, mlp_model: NeuralNetwork, learning_rate: float = 0.001):\n",
    "        super(HybridNetwork, self).__init__()\n",
    "        self.rnn_home = rnn_home_model\n",
    "        self.rnn_away = rnn_away_model\n",
    "        self.mlp = mlp_model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x, x_historical_home, x_historical_away):\n",
    "        \"\"\"Compute y_hat from dataloader input\"\"\"\n",
    "        # 'x' comes in as:                minibatch_size x 1 x num_of_feats\n",
    "        # 'x_historical_*' comes in as:   minibatch_size x 5 x num_of_feats\n",
    "        # 'rnn_*_hidden' will be:         minibatch_size x num_of_feats\n",
    "        batch_size = x.size(0)\n",
    "        time_seq_len = x_historical_home.size(1)\n",
    "        ''' === RNN HOME FORWARD === '''\n",
    "        rnn_home_hidden = self.rnn_home.init_hidden(batch_size)\n",
    "        # print(rnn_home_hidden)\n",
    "        for batch_idx in range(batch_size):\n",
    "            for history_idx in range(time_seq_len):\n",
    "                rnn_home_hidden[batch_idx] = self.rnn_home(\n",
    "                    torch.flatten(x_historical_home[batch_idx, history_idx]),\n",
    "                    rnn_home_hidden[batch_idx])\n",
    "        ''' === RNN AWAY FORWARD === '''\n",
    "        rnn_away_hidden = self.rnn_away.init_hidden(batch_size)\n",
    "        for batch_idx in range(batch_size):\n",
    "            for history_idx in range(time_seq_len):\n",
    "                rnn_away_hidden[batch_idx] = self.rnn_away(\n",
    "                    torch.flatten(x_historical_away[batch_idx, history_idx]),\n",
    "                    rnn_away_hidden[batch_idx])\n",
    "        # print(f'rnn_home: {rnn_home_hidden}, rnn_away: {rnn_away_hidden}')\n",
    "        ''' === MLP FORWARD === '''\n",
    "        x_train = torch.cat([x, rnn_home_hidden, rnn_away_hidden], dim=1)\n",
    "        y_hat = self.mlp(x_train)\n",
    "        return y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, x_historical_home, x_historical_away, y = batch\n",
    "        y_hat = self(x, x_historical_home, x_historical_away)\n",
    "        loss = F.cross_entropy(y_hat, y.to(dtype=torch.float))\n",
    "        tensorboard_logs = {\"train_loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, x_historical_home, x_historical_away, y = batch\n",
    "        y_hat = self(x, x_historical_home, x_historical_away)\n",
    "        test_loss = F.cross_entropy(y_hat, y.to(dtype=torch.float))\n",
    "        return {\"test_loss\": test_loss}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"test_loss\"] for x in outputs]).mean()\n",
    "        logs = {\"test_loss\": avg_loss}\n",
    "        return {\"test_loss\": avg_loss, \"log\": logs, \"progress_bar\": logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.SGD(model.parameters(), lr=self.learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "rnn_home = RNN(input_size=tot_num_of_feats, hidden_size=hidden_size)\n",
    "rnn_away = RNN(input_size=tot_num_of_feats, hidden_size=hidden_size)\n",
    "mlp = NeuralNetwork(hidden_size * 2 + tot_num_of_feats)\n",
    "model = HybridNetwork(rnn_home_model=rnn_home, rnn_away_model=rnn_away, mlp_model=mlp, learning_rate=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model fitting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name     | Type          | Params\n",
      "-------------------------------------------\n",
      "0 | rnn_home | RNN           | 1 M   \n",
      "1 | rnn_away | RNN           | 1 M   \n",
      "2 | mlp      | NeuralNetwork | 4 M   \n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3103e4a54fdd4e4693ec69d8d26303db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatchNotFoundException for idx=2433, switching to idx=167\n",
      "MatchNotFoundException for idx=765, switching to idx=2620\n",
      "MatchNotFoundException for idx=384, switching to idx=1236\n",
      "MatchNotFoundException for idx=1528, switching to idx=3946\n",
      "MatchNotFoundException for idx=385, switching to idx=3908\n",
      "MatchNotFoundException for idx=1902, switching to idx=4463\n",
      "MatchNotFoundException for idx=3804, switching to idx=2070\n",
      "MatchNotFoundException for idx=3042, switching to idx=1355\n",
      "MatchNotFoundException for idx=766, switching to idx=793\n",
      "MatchNotFoundException for idx=1901, switching to idx=3762\n",
      "MatchNotFoundException for idx=2662, switching to idx=1758\n",
      "MatchNotFoundException for idx=386, switching to idx=321\n",
      "MatchNotFoundException for idx=3039, switching to idx=4694\n",
      "MatchNotFoundException for idx=3803, switching to idx=3608\n",
      "MatchNotFoundException for idx=4563, switching to idx=2350\n",
      "MatchNotFoundException for idx=4184, switching to idx=2315\n",
      "MatchNotFoundException for idx=1149, switching to idx=2302\n",
      "MatchNotFoundException for idx=4565, switching to idx=1462\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\"tb_logs\", name=\"football_results\")\n",
    "trainer = pl.Trainer(max_epochs=num_epochs, logger=logger)\n",
    "trainer.fit(model, train_dataloader=train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bb82595361849beb20f12d234dff0fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatchNotFoundException for idx=38, switching to idx=389\n",
      "MatchNotFoundException for idx=99, switching to idx=251\n",
      "MatchNotFoundException for idx=384, switching to idx=755\n",
      "MatchNotFoundException for idx=386, switching to idx=325\n",
      "MatchNotFoundException for idx=389, switching to idx=912\n",
      "MatchNotFoundException for idx=762, switching to idx=1041\n",
      "MatchNotFoundException for idx=777, switching to idx=979\n",
      "MatchNotFoundException for idx=779, switching to idx=48\n",
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'test_loss': tensor(6.5140)}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'test_loss': 6.51402473449707}"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_dataloaders=test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Limitations\n",
    "- We don't have data about new players that come to play in _Serie A_ during the course of the seasons. The model has to learn from zero context how important their contribution is for the outcome of the matches. If we were to considered multiple leagues, we could keep track of player transfers and maintain the history.\n",
    "- We don't have data about cup matches played during the course of the seasons, like _Champions League_, _Europa League_ and _Coppa Italia_. Since they are very prestigious competitions and matches are usually very competitive, teams put a lot of effort in them and therefore can then perform worse in the championship.\n",
    "- We don't have any type of player performance metric like who scored a goal, who was the assist man, red or yellow cards, goalkeeper's saves etc. so the model could face some difficulties in learning which player is important for the team."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}