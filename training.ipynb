{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 910,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from train_utils import AverageMeter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "outputs": [],
   "source": [
    "match_cols = ['season', 'round'] + \\\n",
    "['date', 'time', 'referee', 'home_team', 'away_team', 'hom_score', 'away_score'] + \\\n",
    "['home_team_coach'] + \\\n",
    "['home_player_' + str(i) for i in range(1, 12)] + \\\n",
    "['home_substitute_' + str(i) for i in range(1, 8)] + \\\n",
    "['away_team_coach'] + \\\n",
    "['away_player_' + str(i) for i in range(1, 12)] + \\\n",
    "['away_substitute_' + str(i) for i in range(1, 8)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "outputs": [
    {
     "data": {
      "text/plain": "   season  round  year  month  day  hour  home_score  away_score  \\\n0       0      1  2005      8   27    20           2           1   \n1       0      1  2005      8   27    18           2           1   \n2       0      1  2005      8   28    15           1           1   \n3       0      1  2005      8   28    15           1           1   \n4       0      1  2005      8   28    15           3           0   \n\n   home_player_Sebastien Frey  home_player_Marco Amelia  ...  \\\n0                           1                         0  ...   \n1                           0                         1  ...   \n2                           0                         0  ...   \n3                           0                         0  ...   \n4                           0                         0  ...   \n\n   away_coach_Roberto Mancini  away_coach_Rosario Pergolizzi  \\\n0                           0                              0   \n1                           0                              0   \n2                           0                              0   \n3                           0                              0   \n4                           0                              0   \n\n   away_coach_Serse Cosmi  away_coach_Silvio Baldini  \\\n0                       0                          0   \n1                       0                          0   \n2                       0                          0   \n3                       0                          0   \n4                       0                          0   \n\n   away_coach_Sinisa Mihajlovic  away_coach_Stefano Colantuono  \\\n0                             0                              0   \n1                             0                              0   \n2                             0                              0   \n3                             0                              0   \n4                             0                              0   \n\n   away_coach_Stefano Pioli  away_coach_Walter Alfredo Novellino  \\\n0                         0                                    1   \n1                         0                                    0   \n2                         0                                    0   \n3                         0                                    0   \n4                         0                                    0   \n\n   away_coach_Walter Mazzarri  away_coach_Walter Zenga  \n0                           0                        0  \n1                           0                        0  \n2                           0                        0  \n3                           0                        0  \n4                           0                        0  \n\n[5 rows x 2590 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>season</th>\n      <th>round</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>home_score</th>\n      <th>away_score</th>\n      <th>home_player_Sebastien Frey</th>\n      <th>home_player_Marco Amelia</th>\n      <th>...</th>\n      <th>away_coach_Roberto Mancini</th>\n      <th>away_coach_Rosario Pergolizzi</th>\n      <th>away_coach_Serse Cosmi</th>\n      <th>away_coach_Silvio Baldini</th>\n      <th>away_coach_Sinisa Mihajlovic</th>\n      <th>away_coach_Stefano Colantuono</th>\n      <th>away_coach_Stefano Pioli</th>\n      <th>away_coach_Walter Alfredo Novellino</th>\n      <th>away_coach_Walter Mazzarri</th>\n      <th>away_coach_Walter Zenga</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2005</td>\n      <td>8</td>\n      <td>27</td>\n      <td>20</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2005</td>\n      <td>8</td>\n      <td>27</td>\n      <td>18</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2005</td>\n      <td>8</td>\n      <td>28</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2005</td>\n      <td>8</td>\n      <td>28</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2005</td>\n      <td>8</td>\n      <td>28</td>\n      <td>15</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 2590 columns</p>\n</div>"
     },
     "execution_count": 913,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "outputs": [],
   "source": [
    "# utility methods\n",
    "def get_column_names_containing_str(df: pd.DataFrame, substring: str) -> list[str]:\n",
    "    return df.loc[:, df.columns.str.contains(substring)].columns.values.tolist()\n",
    "\n",
    "\n",
    "def get_team_and_historical_index_from_match_team_id(match_team_id: str) -> (str, str):\n",
    "    match_team_name = re.findall(\"\\s+\", match_team_id)[0]\n",
    "    match_team_index = re.findall(\"\\d+\", match_team_id)[0]\n",
    "    return match_team_name, match_team_index\n",
    "\n",
    "\n",
    "def get_match_by_team_season_round(df: pd.DataFrame, team: str, season: int, round: int) -> pd.DataFrame:\n",
    "    return df[((df[f'home_team_{team}'] == 1) | (df[f'away_team_{team}'] == 1)) & (df['round'] == round) & (df['season'] == season)]\n",
    "\n",
    "\n",
    "def get_last_n_matches_played_by_team_before_round_in_season(df: pd.DataFrame, team: str, season: int, round: int, n: int) -> pd.DataFrame:\n",
    "    last_n_matches = pd.DataFrame()\n",
    "    current_round = round\n",
    "    current_season = season\n",
    "    for i in range(n):\n",
    "        if current_round - 1 > 0:\n",
    "            current_round -= 1\n",
    "        else:\n",
    "            current_season -= 1\n",
    "            current_round = 38\n",
    "        last_n_matches = pd.concat([last_n_matches, get_match_by_team_season_round(df, team, current_season, current_round)])\n",
    "    return last_n_matches\n",
    "\n",
    "\n",
    "def fill_with_padding(source: pd.DataFrame):\n",
    "    if len(source) < 5:\n",
    "        initial_len = len(source)\n",
    "        padding = source.tail(1)\n",
    "        for i in range(5 - len(source)):\n",
    "            source = pd.concat([source, padding], ignore_index=True)\n",
    "        # print(f'padding applied. Initial len: {initial_len} new_len: {len(source)}')\n",
    "    return source\n",
    "\n",
    "\n",
    "def get_playing_home_team_name(row: pd.DataFrame) -> str:\n",
    "    team_columns = row.loc[:, [col for col in row.columns if col.startswith('home_team_')]]\n",
    "    team_name = team_columns.where(team_columns == 1).dropna(axis=1).columns[0].replace('home_team_', '')\n",
    "    return team_name\n",
    "\n",
    "\n",
    "def get_playing_away_team_name(row: pd.DataFrame) -> str:\n",
    "    team_columns = row.loc[:, [col for col in row.columns if col.startswith('away_team_')]]\n",
    "    team_name = team_columns.where(team_columns == 1).dropna(axis=1).columns[0].replace('away_team_', '')\n",
    "    return team_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of encoded features: 2590\n"
     ]
    }
   ],
   "source": [
    "tot_num_of_feats = len(train.columns)\n",
    "print(f'Total number of encoded features: {tot_num_of_feats}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2590)\n",
      "(5, 2590)\n",
      "(5, 2590)\n",
      "(5, 2590)\n",
      "[[   2    2 2007 ...    0    0    0]\n",
      " [   2    1 2007 ...    0    0    0]\n",
      " [   2    1 2007 ...    0    0    0]\n",
      " [   2    1 2007 ...    0    0    0]\n",
      " [   2    1 2007 ...    0    0    0]]\n",
      "[[   2    2 2007 ...    0    0    0]\n",
      " [   2    1 2007 ...    0    0    0]\n",
      " [   1   38 2007 ...    0    0    0]\n",
      " [   1   37 2007 ...    0    0    0]\n",
      " [   1   36 2007 ...    1    0    0]]\n"
     ]
    }
   ],
   "source": [
    "x = train.iloc[[775]]\n",
    "# home_historical_games = get_last_n_matches_played_by_team_before_round_in_season(train, 'GENOVA', 2, 1, 5)\n",
    "home_historical_games = get_last_n_matches_played_by_team_before_round_in_season(train, get_playing_home_team_name(x), x['season'].values[0], x['round'].values[0], 5)\n",
    "away_historical_games = get_last_n_matches_played_by_team_before_round_in_season(train, get_playing_away_team_name(x), x['season'].values[0], x['round'].values[0], 5)\n",
    "print(home_historical_games.shape)\n",
    "print(away_historical_games.shape)\n",
    "home_historical_games = fill_with_padding(home_historical_games)\n",
    "away_historical_games = fill_with_padding(away_historical_games)\n",
    "print(home_historical_games.shape)\n",
    "print(away_historical_games.shape)\n",
    "print(home_historical_games.values)\n",
    "print(away_historical_games.values)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "outputs": [],
   "source": [
    "del train\n",
    "# del lb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset construction\n",
    "\n",
    "We need to define a torch Dataset and torch Dataloader that will be used during training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "outputs": [],
   "source": [
    "class SerieAFootballMatchesDataset(Dataset):\n",
    "    history_len = 5\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(f'picked index {idx}')\n",
    "        idx = self.scale_idx(idx)\n",
    "        x = self.dataframe.iloc[[idx]]  # df\n",
    "        y = self.dataframe[['result_home', 'result_draw', 'result_away']].iloc[0].values\n",
    "        last_n_games_home, last_n_games_away = self.retrieve_historical_data(x)\n",
    "        last_n_games_home = fill_with_padding(last_n_games_home)\n",
    "        last_n_games_away = fill_with_padding(last_n_games_away)\n",
    "        x, x_historical_home, x_historical_away, y = self.to_tensor(x, last_n_games_home, last_n_games_away, y)\n",
    "        return x, x_historical_home, x_historical_away, y\n",
    "\n",
    "    def scale_idx(self, idx: int) -> int:\n",
    "        \"\"\"Scale the given index to a range that allows for historical data retrieval\"\"\"\n",
    "        old_min = 0\n",
    "        old_max = len(self.dataframe)\n",
    "        '''\n",
    "        idx = 10 corresponds to the first match of the second round.\n",
    "        This ensure the retrieval of at least 1 historical match.\n",
    "        In the worst case scenario, padding will fill the other 4 historical slots.\n",
    "        '''\n",
    "        new_min = 10\n",
    "        new_max = old_max\n",
    "        old_range = old_max - old_min\n",
    "        new_range = new_max - new_min\n",
    "        normalized_idx = (idx - old_min) / old_range\n",
    "        return int(round(normalized_idx * new_range + new_min))\n",
    "\n",
    "    def retrieve_historical_data(self, source: pd.DataFrame):\n",
    "        \"\"\"Retrieve historical data for home and away teams from source\"\"\"\n",
    "        last_n_games_home = get_last_n_matches_played_by_team_before_round_in_season(\n",
    "            self.dataframe, get_playing_home_team_name(source), source['season'].values[0], source['round'].values[0], self.history_len)\n",
    "        last_n_games_away = get_last_n_matches_played_by_team_before_round_in_season(\n",
    "            self.dataframe, get_playing_away_team_name(source), source['season'].values[0], source['round'].values[0], self.history_len)\n",
    "        return last_n_games_home, last_n_games_away\n",
    "\n",
    "    def to_tensor(self, x: pd.DataFrame, x_historical_home: pd.DataFrame, x_historical_away: pd.DataFrame,\n",
    "               y: list[int]):\n",
    "        x_tensor = torch.tensor(x.values)\n",
    "        x_historical_home_tensor = torch.tensor(x_historical_home.values)\n",
    "        x_historical_away_tensor = torch.tensor(x_historical_away.values)\n",
    "        y_tensor = torch.tensor(y)\n",
    "        # print(f'x_t: {x_tensor.shape}')\n",
    "        # print(f'x_historical_home_t: {x_historical_home_tensor.shape}')\n",
    "        # print(f'x_historical_away_t: {x_historical_away_tensor.shape}')\n",
    "        # print(f'y_t: {y_tensor.shape}')\n",
    "        return x_tensor, x_historical_home_tensor, x_historical_away_tensor, y_tensor\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat([input, hidden], dim=0)\n",
    "        pre_hidden = self.linear(combined)\n",
    "        hidden = self.tanh(pre_hidden)\n",
    "        return hidden\n",
    "\n",
    "    def init_hidden(self, minibatch_size):\n",
    "        return torch.zeros(minibatch_size, self.hidden_size)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 3),\n",
    "            # nn.Softmax(dim=1) softmax is applied implicitly by CrossEntropyLoss\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 'x' is the combination of: 'x', 'x_historical_home', 'x_historical_away'\n",
    "        # they all have size: minibatch_size x num_of_feats\n",
    "        x = self.flatten(x) # just in case x was not flattened\n",
    "        output = self.layers(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class HybridNetwork(nn.Module):\n",
    "    def __init__(self, rnn_home_model: RNN, rnn_away_model: RNN, mlp_model: NeuralNetwork):\n",
    "        super(HybridNetwork, self).__init__()\n",
    "        self.rnn_home = rnn_home_model\n",
    "        self.rnn_away = rnn_away_model\n",
    "        self.mlp = mlp_model\n",
    "\n",
    "    def forward(self, x, x_historical_home, x_historical_away):\n",
    "        # 'x' comes in as:                minibatch_size x 1 x num_of_feats\n",
    "        # 'x_historical_*' comes in as:   minibatch_size x 5 x num_of_feats\n",
    "        # 'rnn_*_hidden' will be:         minibatch_size x num_of_feats\n",
    "        batch_size = x.size(0)\n",
    "        time_seq_len = x_historical_home.size(1)\n",
    "        # RNN HOME FORWARD\n",
    "        rnn_home_hidden = self.rnn_home.init_hidden(batch_size)\n",
    "        # print(rnn_home_hidden)\n",
    "        for batch_idx in range(batch_size):\n",
    "            for history_idx in range(time_seq_len):\n",
    "                rnn_home_hidden[batch_idx] = self.rnn_home(\n",
    "                    torch.flatten(x_historical_home[batch_idx, history_idx]),\n",
    "                    rnn_home_hidden[batch_idx])\n",
    "        # RNN AWAY FORWARD\n",
    "        rnn_away_hidden = self.rnn_away.init_hidden(batch_size)\n",
    "        for batch_idx in range(batch_size):\n",
    "            for history_idx in range(time_seq_len):\n",
    "                rnn_away_hidden[batch_idx] = self.rnn_away(\n",
    "                    torch.flatten(x_historical_away[batch_idx, history_idx]),\n",
    "                    rnn_away_hidden[batch_idx])\n",
    "        # print(rnn_home_hidden)\n",
    "        # MLP FORWARD\n",
    "        # concat on the features dimension\n",
    "        x_train = torch.cat([x, rnn_home_hidden, rnn_away_hidden], dim=1)\n",
    "        y_hat = self.mlp(x_train)\n",
    "        return y_hat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "outputs": [],
   "source": [
    "def train_epoch(model: HybridNetwork, dataloader: DataLoader, optimizer: optim.Optimizer, loss_fn, loss_meter):\n",
    "    for x, x_historical_home, x_historical_away, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x, x_historical_home, x_historical_away)\n",
    "        # print(f'y: {y}')\n",
    "        # print(f'y_hat: {y_hat}')\n",
    "        loss = loss_fn(y.to(dtype=torch.float), y_hat)\n",
    "        print(f'loss: {loss}')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_meter.update(val=loss.item(), n=x.shape[0])\n",
    "\n",
    "\n",
    "def train_model(model: HybridNetwork, dataloader: DataLoader, optimizer: optim.Optimizer, loss_fn, num_epochs: int):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_meter = AverageMeter()\n",
    "        train_epoch(model=model, dataloader=dataloader, optimizer=optimizer, loss_fn=loss_fn, loss_meter=loss_meter)\n",
    "        print(f\"Epoch {epoch + 1} completed. Training loss: {loss_meter.avg}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "outputs": [],
   "source": [
    "train_dataset = SerieAFootballMatchesDataset(csv_file='train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 3\n",
    "hidden_size = 128\n",
    "rnn_home = RNN(input_size=tot_num_of_feats, hidden_size=hidden_size)\n",
    "rnn_away = RNN(input_size=tot_num_of_feats, hidden_size=hidden_size)\n",
    "# we have two hidden states (for home and away team) plus all features except for 'home_score', 'away_score', 'result_home', 'result_draw' and 'result_away'\n",
    "mlp = NeuralNetwork(hidden_size * 2 + tot_num_of_feats - 5)\n",
    "model = HybridNetwork(rnn_home_model=rnn_home, rnn_away_model=rnn_away, mlp_model=mlp)\n",
    "cross_entropy_loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picked index 945\n",
      "picked index 43\n",
      "picked index 988\n",
      "picked index 1036\n",
      "picked index 929\n",
      "picked index 119\n",
      "picked index 1172\n",
      "picked index 832\n",
      "picked index 760\n",
      "picked index 276\n",
      "picked index 706\n",
      "picked index 68\n",
      "picked index 1201\n",
      "picked index 415\n",
      "picked index 665\n",
      "picked index 735\n",
      "picked index 1288\n",
      "picked index 807\n",
      "picked index 9\n",
      "picked index 714\n",
      "picked index 530\n",
      "picked index 1131\n",
      "picked index 967\n",
      "picked index 871\n",
      "picked index 95\n",
      "picked index 245\n",
      "picked index 1063\n",
      "picked index 105\n",
      "picked index 7\n",
      "picked index 223\n",
      "picked index 329\n",
      "picked index 564\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 3 and 2",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [924]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_entropy_loss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [920]\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, dataloader, optimizer, loss_fn, num_epochs)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m     17\u001B[0m     loss_meter \u001B[38;5;241m=\u001B[39m AverageMeter()\n\u001B[1;32m---> 18\u001B[0m     \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_meter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_meter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m completed. Training loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss_meter\u001B[38;5;241m.\u001B[39mavg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Input \u001B[1;32mIn [920]\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[1;34m(model, dataloader, optimizer, loss_fn, loss_meter)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x, x_historical_home, x_historical_away, y \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[0;32m      3\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 4\u001B[0m     y_hat \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_historical_home\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_historical_away\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# print(f'y: {y}')\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m# print(f'y_hat: {y_hat}')\u001B[39;00m\n\u001B[0;32m      7\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_fn(y\u001B[38;5;241m.\u001B[39mto(dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat), y_hat)\n",
      "File \u001B[1;32mD:\\Windows\\Programmi\\miniconda3\\envs\\footballprediction\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[1;32mIn [919]\u001B[0m, in \u001B[0;36mHybridNetwork.forward\u001B[1;34m(self, x, x_historical_home, x_historical_away)\u001B[0m\n\u001B[0;32m     65\u001B[0m         rnn_away_hidden[batch_idx] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrnn_away(\n\u001B[0;32m     66\u001B[0m             torch\u001B[38;5;241m.\u001B[39mflatten(x_historical_away[batch_idx, history_idx]),\n\u001B[0;32m     67\u001B[0m             rnn_away_hidden[batch_idx])\n\u001B[0;32m     68\u001B[0m \u001B[38;5;66;03m# print(rnn_home_hidden)\u001B[39;00m\n\u001B[0;32m     69\u001B[0m \u001B[38;5;66;03m# MLP FORWARD\u001B[39;00m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;66;03m# concat on the features dimension\u001B[39;00m\n\u001B[1;32m---> 71\u001B[0m x_train \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrnn_home_hidden\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrnn_away_hidden\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     72\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp(x_train)\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y_hat\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Tensors must have same number of dimensions: got 3 and 2"
     ]
    }
   ],
   "source": [
    "train_model(model=model, dataloader=train_dataloader, optimizer=optimizer, loss_fn=cross_entropy_loss_fn, num_epochs=num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Missing data\n",
    "- We don't have data about new players that come to play in _Serie A_ during the course of the seasons. The model has to learn from zero context how important their contribution is for the outcome of the matches. If we were to considered multiple leagues, we could keep track of player transfers and maintain the history.\n",
    "- We don't have data about cup matches played during the course of the seasons, like _Champions League_, _Europa League_ and _Coppa Italia_. Since they are very prestigious competitions and matches are usually very competitive, teams put a lot of effort in them and therefore can then perform worse in the championship.\n",
    "- We don't have any type of player performance metric like who scored a goal, who was the assist man, red or yellow cards, goalkeeper's saves etc. so the model could face some difficulties in learning which player is important for the team."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}