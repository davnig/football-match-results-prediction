{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1920,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from train_utils import AverageMeter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1921,
   "outputs": [],
   "source": [
    "match_cols = ['season', 'round'] + \\\n",
    "['date', 'time', 'referee', 'home_team', 'away_team', 'home_team_score', 'away_team_score'] + \\\n",
    "['home_team_coach'] + \\\n",
    "['home_player_' + str(i) for i in range(1, 12)] + \\\n",
    "['home_substitute_' + str(i) for i in range(1, 8)] + \\\n",
    "['away_team_coach'] + \\\n",
    "['away_player_' + str(i) for i in range(1, 12)] + \\\n",
    "['away_substitute_' + str(i) for i in range(1, 8)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1922,
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1923,
   "outputs": [
    {
     "data": {
      "text/plain": "   season  round  year  month  day  hour  home_team_score  away_team_score  \\\n0       0      1  2005      8   27    20                2                1   \n1       0      1  2005      8   27    18                2                1   \n2       0      1  2005      8   28    15                1                1   \n3       0      1  2005      8   28    15                1                1   \n4       0      1  2005      8   28    15                3                0   \n\n   referee_ANDREA DE  referee_ANDREA GERVASONI  ...  \\\n0                  0                         0  ...   \n1                  0                         0  ...   \n2                  0                         0  ...   \n3                  0                         0  ...   \n4                  0                         0  ...   \n\n   away_substitute_7_Vitaliy Kutuzov  away_substitute_7_Vitorino Antunes  \\\n0                                  0                                   0   \n1                                  0                                   0   \n2                                  0                                   0   \n3                                  0                                   0   \n4                                  0                                   0   \n\n   away_substitute_7_Vittorio Tosto  away_substitute_7_Walter Samuel  \\\n0                                 0                                0   \n1                                 0                                0   \n2                                 0                                0   \n3                                 0                                0   \n4                                 0                                0   \n\n   away_substitute_7_Willy Aubameyang  away_substitute_7_Wilson  \\\n0                                   0                         0   \n1                                   0                         0   \n2                                   0                         0   \n3                                   0                         0   \n4                                   0                         0   \n\n   away_substitute_7_Xhulian Rrudho  away_substitute_7_Yoann Gourcuff  \\\n0                                 0                                 0   \n1                                 0                                 0   \n2                                 0                                 0   \n3                                 0                                 0   \n4                                 0                                 0   \n\n   away_substitute_7_Zdravko Kuzmanovic  away_substitute_7_Zlatan Muslimovic  \n0                                     0                                    0  \n1                                     0                                    0  \n2                                     0                                    0  \n3                                     0                                    0  \n4                                     0                                    0  \n\n[5 rows x 11307 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>season</th>\n      <th>round</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>home_team_score</th>\n      <th>away_team_score</th>\n      <th>referee_ANDREA DE</th>\n      <th>referee_ANDREA GERVASONI</th>\n      <th>...</th>\n      <th>away_substitute_7_Vitaliy Kutuzov</th>\n      <th>away_substitute_7_Vitorino Antunes</th>\n      <th>away_substitute_7_Vittorio Tosto</th>\n      <th>away_substitute_7_Walter Samuel</th>\n      <th>away_substitute_7_Willy Aubameyang</th>\n      <th>away_substitute_7_Wilson</th>\n      <th>away_substitute_7_Xhulian Rrudho</th>\n      <th>away_substitute_7_Yoann Gourcuff</th>\n      <th>away_substitute_7_Zdravko Kuzmanovic</th>\n      <th>away_substitute_7_Zlatan Muslimovic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2005</td>\n      <td>8</td>\n      <td>27</td>\n      <td>20</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2005</td>\n      <td>8</td>\n      <td>27</td>\n      <td>18</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2005</td>\n      <td>8</td>\n      <td>28</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2005</td>\n      <td>8</td>\n      <td>28</td>\n      <td>15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2005</td>\n      <td>8</td>\n      <td>28</td>\n      <td>15</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 11307 columns</p>\n</div>"
     },
     "execution_count": 1923,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1882,
   "outputs": [],
   "source": [
    "# utility methods\n",
    "def get_column_names_containing_str(df: pd.DataFrame, substring: str) -> list[str]:\n",
    "    return df.loc[:, df.columns.str.contains(substring)].columns.values.tolist()\n",
    "\n",
    "\n",
    "def get_team_and_historical_index_from_match_team_id(match_team_id: str) -> (str, str):\n",
    "    match_team_name = re.findall(\"\\s+\", match_team_id)[0]\n",
    "    match_team_index = re.findall(\"\\d+\", match_team_id)[0]\n",
    "    return match_team_name, match_team_index\n",
    "\n",
    "\n",
    "def get_match_by_team_season_round(df: pd.DataFrame, team: str, season: int, round: int) -> pd.DataFrame:\n",
    "    return df[((df[f'home_team_{team}'] == 1) | (df[f'away_team_{team}'] == 1)) & (df['round'] == round) & (df['season'] == season)]\n",
    "\n",
    "\n",
    "def get_last_n_matches_played_by_team_before_round_in_season(df: pd.DataFrame, team: str, season: int, round: int, n: int) -> pd.DataFrame:\n",
    "    last_n_matches = pd.DataFrame()\n",
    "    for i in range(1, n + 1):\n",
    "        if round - i > 0:\n",
    "            last_n_matches = pd.concat([last_n_matches, get_match_by_team_season_round(df, team, season, round - i)])\n",
    "    return last_n_matches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data encoding\n",
    "We need to encode the data before feeding it to the network. Here we define encoding methods that returns pytorch Tensors."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Seasons and Rounds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1883,
   "outputs": [],
   "source": [
    "# class SeasonRoundEncoder(object):\n",
    "#     \"\"\"Encode the season and round columns of the given pandas DataFrame sample\"\"\"\n",
    "#\n",
    "#     def __init__(self, season_dict_map: dict):\n",
    "#         self.mapping = season_dict_map\n",
    "#\n",
    "#     def __call__(self, sample: pd.DataFrame) -> torch.tensor:\n",
    "#         season_encoding = torch.tensor([[el] for el in sample['season'].map(self.mapping).tolist()], dtype=torch.int32)\n",
    "#         round_encoding = torch.tensor([[el] for el in sample['round'].tolist()], dtype=torch.int32)\n",
    "#         return torch.cat([season_encoding, round_encoding], 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1884,
   "outputs": [],
   "source": [
    "# season2index = {'20' + f'{i + 5}'.zfill(2) + '-' + f'{i + 6}'.zfill(2): i for i in range(16)}\n",
    "# season_round_encoder = SeasonRoundEncoder(season2index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1885,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEASONS and ROUNDS encoding OK\n"
     ]
    }
   ],
   "source": [
    "# # TEST seasons and rounds encoding\n",
    "# tensor = season_round_encoder(df.iloc[0:2])\n",
    "# seasons_rounds_expected_num_of_feats = 2\n",
    "# if tensor.shape[1] == seasons_rounds_expected_num_of_feats:\n",
    "#     print('SEASONS and ROUNDS encoding OK')\n",
    "# else:\n",
    "#     print(f'num of features: {tensor.shape[1]}')\n",
    "#     print(f'expected num of features: {seasons_rounds_expected_num_of_feats}')\n",
    "#     raise Exception('SEASONS and ROUNDS encoding NOT OK! :(')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Datetime values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1886,
   "outputs": [],
   "source": [
    "# class DatetimeEncoder(object):\n",
    "#     \"\"\"Encode the year, month, day and hour columns of the given pandas DataFrame sample\"\"\"\n",
    "#\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "#\n",
    "#     def __call__(self, sample: pd.DataFrame) -> torch.tensor:\n",
    "#         year_encoding = torch.tensor([[el] for el in sample['year'].tolist()], dtype=torch.int32)\n",
    "#         month_encoding = torch.tensor([[el] for el in sample['month'].tolist()], dtype=torch.int32)\n",
    "#         day_encoding = torch.tensor([[el] for el in sample['day'].tolist()], dtype=torch.int32)\n",
    "#         hour_encoding = torch.tensor([[el] for el in sample['hour'].tolist()], dtype=torch.int32)\n",
    "#         return torch.cat([year_encoding, month_encoding, day_encoding, hour_encoding], 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1887,
   "outputs": [],
   "source": [
    "# datetime_encoder = DatetimeEncoder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1888,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATETIME encoding OK\n"
     ]
    }
   ],
   "source": [
    "# # TEST datetime values encoding\n",
    "# tensor = datetime_encoder(df.iloc[0:2])\n",
    "# datetime_expected_num_of_feats = 4\n",
    "# if tensor.shape[1] == datetime_expected_num_of_feats:\n",
    "#     print('DATETIME encoding OK')\n",
    "# else:\n",
    "#     print(f'num of features: {tensor.shape[1]}')\n",
    "#     print(f'expected num of features: {datetime_expected_num_of_feats}')\n",
    "#     raise Exception('DATETIME encoding NOT OK! :(')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Results\n",
    "One-hot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1889,
   "outputs": [],
   "source": [
    "# class ResultEncoder(object):\n",
    "#     \"\"\"Encode the result column of the given pandas DataFrame sample\"\"\"\n",
    "#\n",
    "#     def __init__(self, dict_map: dict):\n",
    "#         self.mapping = dict_map\n",
    "#\n",
    "#     def __call__(self, sample: pd.DataFrame) -> torch.LongTensor:\n",
    "#         return torch.LongTensor(sample['result'].map(self.mapping).tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1890,
   "outputs": [],
   "source": [
    "# result2onehot = {'home': [1, 0, 0], 'draw': [0, 1, 0], 'away': [0, 0, 1]}\n",
    "# result_encoder = ResultEncoder(result2onehot)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1891,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0],\n",
      "        [1, 0, 0]])\n",
      "<class 'torch.Tensor'>\n",
      "RESULT encoding OK\n"
     ]
    }
   ],
   "source": [
    "# # TEST results encoding\n",
    "# tensor = result_encoder(df.iloc[0:2])\n",
    "# print(tensor)\n",
    "# print(type(tensor.to(torch.long)))\n",
    "# results_expected_num_of_feats = len(df['result'].unique())\n",
    "# if tensor.shape[1] == results_expected_num_of_feats:\n",
    "#     print('RESULT encoding OK')\n",
    "# else:\n",
    "#     print(f'num of features: {tensor.shape[1]}')\n",
    "#     print(f'expected num of features: {results_expected_num_of_feats}')\n",
    "#     raise Exception('RESULT encoding NOT OK! :(')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Referees\n",
    "One-hot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1892,
   "outputs": [],
   "source": [
    "# class RefereeEncoder(object):\n",
    "#     \"\"\"Encode the referee column of the given pandas DataFrame sample\"\"\"\n",
    "#\n",
    "#     def __init__(self, lb: LabelBinarizer):\n",
    "#         self.lb = lb\n",
    "#\n",
    "#     def __call__(self, sample: pd.DataFrame) -> torch.tensor:\n",
    "#         return torch.tensor(self.lb.transform(sample['referee'].tolist()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1893,
   "outputs": [],
   "source": [
    "# lb = LabelBinarizer()\n",
    "# fitted_lb = lb.fit(df['referee'].tolist())\n",
    "# referee_encoder = RefereeEncoder(fitted_lb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1894,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REFEREE encoding OK\n"
     ]
    }
   ],
   "source": [
    "# # TEST referees encoding\n",
    "# tensor = referee_encoder(df.iloc[0:2])\n",
    "# referees_expected_num_of_feats = len(df['referee'].unique())\n",
    "# if tensor.shape[1] == referees_expected_num_of_feats:\n",
    "#     print('REFEREE encoding OK')\n",
    "# else:\n",
    "#     print(f'num of features: {tensor.shape[1]}')\n",
    "#     print(f'expected num of features: {referees_expected_num_of_feats}')\n",
    "#     raise Exception('REFEREE encoding NOT OK! :(')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Teams\n",
    "One-hot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1895,
   "outputs": [],
   "source": [
    "# class TeamsEncoder(object):\n",
    "#     \"\"\"Encode the home_team and away_team columns of the given pandas DataFrame sample\"\"\"\n",
    "#\n",
    "#     def __init__(self, lb: LabelBinarizer):\n",
    "#         self.lb = lb\n",
    "#\n",
    "#     def __call__(self, sample: pd.DataFrame) -> torch.tensor:\n",
    "#         home_encoding = torch.tensor(self.lb.transform(sample['home_team'].tolist()))\n",
    "#         away_encoding = torch.tensor(self.lb.transform(sample['away_team'].tolist()))\n",
    "#         return torch.cat([home_encoding, away_encoding], 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1896,
   "outputs": [],
   "source": [
    "# lb = LabelBinarizer()\n",
    "# # every team has played as home team at least once\n",
    "# fitted_lb = lb.fit(df['home_team'].tolist())\n",
    "# teams_encoder = TeamsEncoder(fitted_lb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1897,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEAMS encoding OK\n"
     ]
    }
   ],
   "source": [
    "# # TEST teams encoding\n",
    "# tensor = teams_encoder(df.iloc[0:2])\n",
    "# teams_expected_num_of_feats = len(df['home_team'].unique()) * 2\n",
    "# if tensor.shape[1] == teams_expected_num_of_feats:\n",
    "#     print('TEAMS encoding OK')\n",
    "# else:\n",
    "#     print(f'num of features: {tensor.shape[1]}')\n",
    "#     print(f'expected num of features: {teams_expected_num_of_feats}')\n",
    "#     raise Exception('TEAMS encoding NOT OK! :(')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Coaches\n",
    "One-hot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1898,
   "outputs": [],
   "source": [
    "# class CoachesEncoder(object):\n",
    "#     \"\"\"Encode the home_team_coach and away_team_coach columns of the given pandas DataFrame sample\"\"\"\n",
    "#\n",
    "#     def __init__(self, lb: LabelBinarizer):\n",
    "#         self.lb = lb\n",
    "#\n",
    "#     def __call__(self, sample: pd.DataFrame) -> torch.tensor:\n",
    "#         home_coach_encoding = torch.tensor(self.lb.transform(sample['home_team_coach'].tolist()))\n",
    "#         away_coach_encoding = torch.tensor(self.lb.transform(sample['away_team_coach'].tolist()))\n",
    "#         return torch.cat([home_coach_encoding, away_coach_encoding], 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1899,
   "outputs": [],
   "source": [
    "# lb = LabelBinarizer()\n",
    "# # every team has played as home team at least once, so home_team_coach already contains all the coaches\n",
    "# fitted_lb = lb.fit(df['home_team_coach'].tolist())\n",
    "# coaches_encoder = CoachesEncoder(fitted_lb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1900,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COACH encoding OK\n"
     ]
    }
   ],
   "source": [
    "# # TEST coaches encoding\n",
    "# tensor = coaches_encoder(df.iloc[0:2])\n",
    "# coaches_expected_num_of_feats = len(df['home_team_coach'].unique()) * 2\n",
    "# if tensor.shape[1] == coaches_expected_num_of_feats:\n",
    "#     print('COACH encoding OK')\n",
    "# else:\n",
    "#     print(f'num of features: {tensor.shape[1]}')\n",
    "#     print(f'expected num of features: {coaches_expected_num_of_feats}')\n",
    "#     raise Exception('COACH encoding NOT OK! :(')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Players\n",
    "One-hot encoding. We treat all players equally, both those that are part of the lineup and the substitutes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1901,
   "outputs": [],
   "source": [
    "# class PlayersEncoder(object):\n",
    "#     \"\"\"Encode the home and away team lineup and substitute players of the given pandas DataFrame sample\"\"\"\n",
    "#\n",
    "#     def __init__(self, lb: LabelBinarizer):\n",
    "#         self.lb = lb\n",
    "#\n",
    "#     def __call__(self, sample: pd.DataFrame) -> torch.tensor:\n",
    "#         result = []\n",
    "#         for i in range(1, 12):\n",
    "#             result += [torch.tensor(self.lb.transform(sample[f'home_player_{i}'].tolist()))]\n",
    "#         for i in range(1, 8):\n",
    "#             result += [torch.tensor(self.lb.transform(sample[f'home_substitute_{i}'].tolist()))]\n",
    "#         for i in range(1, 12):\n",
    "#             result += [torch.tensor(self.lb.transform(sample[f'away_player_{i}'].tolist()))]\n",
    "#         for i in range(1, 8):\n",
    "#             result += [torch.tensor(self.lb.transform(sample[f'away_substitute_{i}'].tolist()))]\n",
    "#         return torch.cat(result, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1902,
   "outputs": [],
   "source": [
    "# def flatten_list(list_of_lists: list[list[str]]) -> list[str]:\n",
    "#     return [item for sublist in list_of_lists for item in sublist]\n",
    "#\n",
    "#\n",
    "# def encode_fit_players(source_df: pd.DataFrame) -> LabelBinarizer:\n",
    "#     lb = LabelBinarizer()\n",
    "#     player_cols = get_column_names_containing_str(source_df, 'home_player')\n",
    "#     player_cols += get_column_names_containing_str(source_df, 'home_substitute')\n",
    "#     all_players_unflattened = source_df.loc[:, player_cols].values.tolist()\n",
    "#     all_players_flattened = flatten_list(all_players_unflattened)\n",
    "#     lb.fit(all_players_flattened)\n",
    "#     return lb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1903,
   "outputs": [],
   "source": [
    "# lb = LabelBinarizer()\n",
    "# fitted_lb = encode_fit_players(df)\n",
    "# players_encoder = PlayersEncoder(fitted_lb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1904,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAYER encoding OK\n"
     ]
    }
   ],
   "source": [
    "# # TEST players encoding\n",
    "# player_cols = get_column_names_containing_str(df, 'home_player')\n",
    "# player_cols += get_column_names_containing_str(df, 'home_substitute')\n",
    "# tensor = players_encoder(df.iloc[0:2])\n",
    "# all_unique_player_names = pd.concat([df[player_cols[i]] for i in range(len(player_cols))], axis=0).unique()\n",
    "# players_expected_num_of_feats = len(all_unique_player_names) * (11 + 7) * 2\n",
    "# if tensor.shape[1] == players_expected_num_of_feats:\n",
    "#     print('PLAYER encoding OK')\n",
    "# else:\n",
    "#     print(f'num of features: {tensor.shape[1]}')\n",
    "#     print(f'expected num of features: {players_expected_num_of_feats}')\n",
    "#     raise Exception('PLAYER encoding NOT OK! :(')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1905,
   "outputs": [],
   "source": [
    "# class Encode(object):\n",
    "#     \"\"\"Encode the given pandas DataFrame sample and return a pytorch Tensor\"\"\"\n",
    "#\n",
    "#     def __init__(self, season_round_enc: SeasonRoundEncoder, datetime_enc: DatetimeEncoder,\n",
    "#                  result_enc: ResultEncoder, referee_enc: RefereeEncoder, teams_enc: TeamsEncoder,\n",
    "#                  coaches_enc: CoachesEncoder, players_enc: PlayersEncoder,\n",
    "#                  keep_scores: bool, keep_result: bool):\n",
    "#         self.season_round_encoder = season_round_enc\n",
    "#         self.datetime_encoder = datetime_enc\n",
    "#         self.result_encoder = result_enc\n",
    "#         self.referee_encoder = referee_enc\n",
    "#         self.teams_encoder = teams_enc\n",
    "#         self.coaches_encoder = coaches_enc\n",
    "#         self.players_encoder = players_enc\n",
    "#         self.keep_scores = keep_scores\n",
    "#         self.keep_result = keep_result\n",
    "#\n",
    "#     def __call__(self, sample: pd.DataFrame) -> torch.tensor:\n",
    "#         encoded = torch.cat((\n",
    "#             self.season_round_encoder(sample),\n",
    "#             self.datetime_encoder(sample),\n",
    "#             self.referee_encoder(sample),\n",
    "#             self.teams_encoder(sample),\n",
    "#             self.coaches_encoder(sample),\n",
    "#             self.players_encoder(sample)\n",
    "#         ), dim=1)\n",
    "#         # print(encoded)\n",
    "#         if self.keep_scores:\n",
    "#             encoded = self.add_encoded_scores(encoded, sample)\n",
    "#         if self.keep_result:\n",
    "#             return self.add_encoded_result(encoded, sample)\n",
    "#         return encoded\n",
    "#\n",
    "#     def add_encoded_scores(self, target: torch.tensor, source: pd.DataFrame) -> torch.tensor:\n",
    "#         return torch.cat([\n",
    "#             target,\n",
    "#             torch.tensor([[el] for el in source['home_team_score'].tolist()], dtype=torch.int32),\n",
    "#             torch.tensor([[el] for el in source['away_team_score'].tolist()], dtype=torch.int32)\n",
    "#         ], 1)\n",
    "#\n",
    "#     def add_encoded_result(self, target: torch.tensor, source: pd.DataFrame) -> torch.tensor:\n",
    "#         return torch.cat([target, self.result_encoder(source)], 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1906,
   "outputs": [],
   "source": [
    "# full_encoder = Encode(season_round_encoder, datetime_encoder, result_encoder, referee_encoder, teams_encoder,\n",
    "#                       coaches_encoder, players_encoder, True, True)\n",
    "#\n",
    "# no_result_encoder = Encode(season_round_encoder, datetime_encoder, result_encoder, referee_encoder, teams_encoder,\n",
    "#                            coaches_encoder, players_encoder, True, False)\n",
    "#\n",
    "# basic_encoder = Encode(season_round_encoder, datetime_encoder, result_encoder, referee_encoder, teams_encoder,\n",
    "#                        coaches_encoder, players_encoder, False, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1907,
   "outputs": [],
   "source": [
    "# scores_expected_num_of_feats = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1908,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding OK\n"
     ]
    }
   ],
   "source": [
    "# # print train tensor example\n",
    "# test_sample = df.iloc[0:2]\n",
    "# test_encoded_sample = full_encoder(test_sample)\n",
    "# total_num_of_features = seasons_rounds_expected_num_of_feats + \\\n",
    "# datetime_expected_num_of_feats + \\\n",
    "# results_expected_num_of_feats + \\\n",
    "# referees_expected_num_of_feats + \\\n",
    "# teams_expected_num_of_feats + \\\n",
    "# coaches_expected_num_of_feats + \\\n",
    "# players_expected_num_of_feats + \\\n",
    "# scores_expected_num_of_feats\n",
    "# if test_encoded_sample.shape[1] == total_num_of_features:\n",
    "#     print(\"encoding OK\")\n",
    "# else:\n",
    "#     print(f'num of features: {test_encoded_sample.shape[1]}')\n",
    "#     print(f'expected num of features: {total_num_of_features}')\n",
    "#     raise Exception(\"encoding NOT OK\")\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1909,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of encoded features: 39912\n"
     ]
    }
   ],
   "source": [
    "tot_num_of_feats = len(train.columns)\n",
    "print(f'Total number of encoded features: {tot_num_of_feats}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1910,
   "outputs": [],
   "source": [
    "del train\n",
    "# del lb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1911,
   "outputs": [],
   "source": [
    "# todo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset construction\n",
    "\n",
    "We need to define a torch Dataset and torch Dataloader that will be used during training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1912,
   "outputs": [],
   "source": [
    "def fill_with_padding(source: pd.DataFrame):\n",
    "    if len(source) < 5:\n",
    "        initial_len = len(source)\n",
    "        padding = source.tail(1)\n",
    "        for i in range(5 - len(source)):\n",
    "            source = pd.concat([source, padding], ignore_index=True)\n",
    "        # print(f'padding applied. Initial len: {initial_len} new_len: {len(source)}')\n",
    "    return source\n",
    "\n",
    "\n",
    "class SerieAFootballMatchesDataset(Dataset):\n",
    "    history_len = 5\n",
    "\n",
    "    def __init__(self, csv_file):\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(f'picked index {idx}')\n",
    "        idx = self.scale_idx(idx)\n",
    "        x_as_df = self.dataframe.iloc[[idx]]  # df\n",
    "        x = self.dataframe.loc[idx]  # series\n",
    "        # encoder expects a dataframe with a 'result' column\n",
    "        y = self.dataframe[['result_home', 'result_draw', 'result_home']]\n",
    "        last_n_games_home, last_n_games_away = self.retrieve_historical_data(x)\n",
    "        last_n_games_home = fill_with_padding(last_n_games_home)\n",
    "        last_n_games_away = fill_with_padding(last_n_games_away)\n",
    "        x, x_historical_home, x_historical_away, y = self.to_tensor(x_as_df, last_n_games_home, last_n_games_away, y)\n",
    "        return x, x_historical_home, x_historical_away, y\n",
    "\n",
    "    def scale_idx(self, idx: int) -> int:\n",
    "        \"\"\"Scale the given index to a range that allows for historical data retrieval\"\"\"\n",
    "        old_min = 0\n",
    "        old_max = len(self.dataframe)\n",
    "        '''\n",
    "        idx = 10 corresponds to the first match of the second round.\n",
    "        This ensure the retrieval of at least 1 historical match.\n",
    "        In the worst case scenario, padding will fill the other 4 historical slots.\n",
    "        '''\n",
    "        new_min = 10\n",
    "        new_max = old_max\n",
    "        old_range = old_max - old_min\n",
    "        new_range = new_max - new_min\n",
    "        normalized_idx = (idx - old_min) / old_range\n",
    "        return int(round(normalized_idx * new_range + new_min))\n",
    "\n",
    "    def retrieve_historical_data(self, source: pd.DataFrame):\n",
    "        \"\"\"Retrieve historical data for home and away teams from source\"\"\"\n",
    "        last_n_games_home = get_last_n_matches_played_by_team_before_round_in_season(\n",
    "            self.dataframe, source['home_team'], source['season'], source['round'], self.history_len)\n",
    "        last_n_games_away = get_last_n_matches_played_by_team_before_round_in_season(\n",
    "            self.dataframe, source['away_team'], source['season'], source['round'], self.history_len)\n",
    "        return last_n_games_home, last_n_games_away\n",
    "\n",
    "    def to_tensor(self, x: pd.DataFrame, x_historical_home: pd.DataFrame, x_historical_away: pd.DataFrame,\n",
    "               y: pd.DataFrame):\n",
    "        x_tensor = torch.tensor(x.values)\n",
    "        x_historical_home_tensor = torch.tensor(x_historical_home)\n",
    "        x_historical_away_tensor = torch.tensor(x_historical_away)\n",
    "        y_tensor = torch.tensor(y)\n",
    "        return x_tensor, x_historical_home_tensor, x_historical_away_tensor, y_tensor\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1913,
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat([input, hidden], dim=0)\n",
    "        pre_hidden = self.linear(combined)\n",
    "        hidden = self.tanh(pre_hidden)\n",
    "        return hidden\n",
    "\n",
    "    def init_hidden(self, minibatch_size):\n",
    "        return torch.zeros(minibatch_size, self.hidden_size)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 3),\n",
    "            # nn.Softmax(dim=1) softmax is applied implicitly by CrossEntropyLoss\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 'x' is the combination of: 'x', 'x_historical_home', 'x_historical_away'\n",
    "        # they all have size: minibatch_size x num_of_feats\n",
    "        x = self.flatten(x) # just in case x was not flattened\n",
    "        output = self.layers(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class HybridNetwork(nn.Module):\n",
    "    def __init__(self, rnn_home_model: RNN, rnn_away_model: RNN, mlp_model: NeuralNetwork):\n",
    "        super(HybridNetwork, self).__init__()\n",
    "        self.rnn_home = rnn_home_model\n",
    "        self.rnn_away = rnn_away_model\n",
    "        self.mlp = mlp_model\n",
    "\n",
    "    def forward(self, x, x_historical_home, x_historical_away):\n",
    "        # 'x' comes in as:                minibatch_size x 1 x num_of_feats\n",
    "        # 'x_historical_*' comes in as:   minibatch_size x 5 x num_of_feats\n",
    "        # 'rnn_*_hidden' will be:         minibatch_size x num_of_feats\n",
    "        batch_size = x.size(0)\n",
    "        time_seq_len = x_historical_home.size(1)\n",
    "        # RNN HOME FORWARD\n",
    "        rnn_home_hidden = self.rnn_home.init_hidden(batch_size)\n",
    "        # print(rnn_home_hidden)\n",
    "        for batch_idx in range(batch_size):\n",
    "            for history_idx in range(time_seq_len):\n",
    "                rnn_home_hidden[batch_idx] = self.rnn_home(\n",
    "                    torch.flatten(x_historical_home[batch_idx, history_idx]),\n",
    "                    rnn_home_hidden[batch_idx])\n",
    "        # RNN AWAY FORWARD\n",
    "        rnn_away_hidden = self.rnn_away.init_hidden(batch_size)\n",
    "        for batch_idx in range(batch_size):\n",
    "            for history_idx in range(time_seq_len):\n",
    "                rnn_away_hidden[batch_idx] = self.rnn_away(\n",
    "                    torch.flatten(x_historical_away[batch_idx, history_idx]),\n",
    "                    rnn_away_hidden[batch_idx])\n",
    "        # print(rnn_home_hidden)\n",
    "        # MLP FORWARD\n",
    "        # concat on the features dimension\n",
    "        x_train = torch.cat([x, rnn_home_hidden, rnn_away_hidden], dim=1)\n",
    "        print(f'x_train shape: {x_train.shape}')\n",
    "        y_hat = self.mlp(x_train)\n",
    "        return y_hat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1914,
   "outputs": [],
   "source": [
    "def train_epoch(model: HybridNetwork, dataloader: DataLoader, optimizer: optim.Optimizer, loss_fn, loss_meter):\n",
    "    for x, x_historical_home, x_historical_away, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x, x_historical_home, x_historical_away)\n",
    "        # print(f'y: {y}')\n",
    "        # print(f'y_hat: {y_hat}')\n",
    "        loss = loss_fn(y.to(dtype=torch.float), y_hat)\n",
    "        print(f'loss: {loss}')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_meter.update(val=loss.item(), n=x.shape[0])\n",
    "\n",
    "\n",
    "def train_model(model: HybridNetwork, dataloader: DataLoader, optimizer: optim.Optimizer, loss_fn, num_epochs: int):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_meter = AverageMeter()\n",
    "        train_epoch(model=model, dataloader=dataloader, optimizer=optimizer, loss_fn=loss_fn, loss_meter=loss_meter)\n",
    "        print(f\"Epoch {epoch + 1} completed. Training loss: {loss_meter.avg}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1915,
   "outputs": [],
   "source": [
    "train_dataset = SerieAFootballMatchesDataset(csv_file='train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1916,
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1917,
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 3\n",
    "hidden_size = 128\n",
    "rnn_home = RNN(input_size=tot_num_of_feats, hidden_size=hidden_size)\n",
    "rnn_away = RNN(input_size=tot_num_of_feats, hidden_size=hidden_size)\n",
    "# we have two hidden states (for home and away team) plus all features except for 'home_score', 'away_score', 'result_home', 'result_draw' and 'result_away'\n",
    "mlp = NeuralNetwork(hidden_size * 2 + tot_num_of_feats - 5)\n",
    "model = HybridNetwork(rnn_home_model=rnn_home, rnn_away_model=rnn_away, mlp_model=mlp)\n",
    "cross_entropy_loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1918,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'season'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Windows\\Programmi\\miniconda3\\envs\\footballprediction\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mD:\\Windows\\Programmi\\miniconda3\\envs\\footballprediction\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\Windows\\Programmi\\miniconda3\\envs\\footballprediction\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'season'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1918]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcross_entropy_loss_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [1914]\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, dataloader, optimizer, loss_fn, num_epochs)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m     17\u001B[0m     loss_meter \u001B[38;5;241m=\u001B[39m AverageMeter()\n\u001B[1;32m---> 18\u001B[0m     \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_meter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_meter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m completed. Training loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss_meter\u001B[38;5;241m.\u001B[39mavg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Input \u001B[1;32mIn [1914]\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[1;34m(model, dataloader, optimizer, loss_fn, loss_meter)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_epoch\u001B[39m(model: HybridNetwork, dataloader: DataLoader, optimizer: optim\u001B[38;5;241m.\u001B[39mOptimizer, loss_fn, loss_meter):\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m x, x_historical_home, x_historical_away, y \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[0;32m      3\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m      4\u001B[0m         y_hat \u001B[38;5;241m=\u001B[39m model(x, x_historical_home, x_historical_away)\n",
      "File \u001B[1;32mD:\\Windows\\Programmi\\miniconda3\\envs\\footballprediction\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 530\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    533\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    534\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mD:\\Windows\\Programmi\\miniconda3\\envs\\footballprediction\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    569\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 570\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    572\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data)\n",
      "File \u001B[1;32mD:\\Windows\\Programmi\\miniconda3\\envs\\footballprediction\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\Windows\\Programmi\\miniconda3\\envs\\footballprediction\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Input \u001B[1;32mIn [1912]\u001B[0m, in \u001B[0;36mSerieAFootballMatchesDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     32\u001B[0m last_n_games_away \u001B[38;5;241m=\u001B[39m fill_with_padding(last_n_games_away)\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m# try:\u001B[39;00m\n\u001B[1;32m---> 34\u001B[0m x, x_historical_home, x_historical_away, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_as_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlast_n_games_home\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlast_n_games_away\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x, x_historical_home, x_historical_away, y\n",
      "Input \u001B[1;32mIn [1912]\u001B[0m, in \u001B[0;36mSerieAFootballMatchesDataset.encode\u001B[1;34m(self, x, x_historical_home, x_historical_away, y)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mencode\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: pd\u001B[38;5;241m.\u001B[39mDataFrame, x_historical_home: pd\u001B[38;5;241m.\u001B[39mDataFrame, x_historical_away: pd\u001B[38;5;241m.\u001B[39mDataFrame,\n\u001B[0;32m     65\u001B[0m            y: pd\u001B[38;5;241m.\u001B[39mDataFrame):\n\u001B[0;32m     66\u001B[0m     \u001B[38;5;124;03m\"\"\"Encode the data\"\"\"\u001B[39;00m\n\u001B[1;32m---> 67\u001B[0m     x_historical_home_encoded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx_historical_encoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_historical_home\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m     x_historical_away_encoded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx_historical_encoder(x_historical_away)\n\u001B[0;32m     69\u001B[0m     x_encoded \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mflatten(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx_encoder(x))\n",
      "Input \u001B[1;32mIn [1905]\u001B[0m, in \u001B[0;36mEncode.__call__\u001B[1;34m(self, sample)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, sample: pd\u001B[38;5;241m.\u001B[39mDataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor:\n\u001B[0;32m     19\u001B[0m     encoded \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((\n\u001B[1;32m---> 20\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseason_round_encoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m     21\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatetime_encoder(sample),\n\u001B[0;32m     22\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreferee_encoder(sample),\n\u001B[0;32m     23\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mteams_encoder(sample),\n\u001B[0;32m     24\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoaches_encoder(sample),\n\u001B[0;32m     25\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mplayers_encoder(sample)\n\u001B[0;32m     26\u001B[0m     ), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;66;03m# print(encoded)\u001B[39;00m\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkeep_scores:\n",
      "Input \u001B[1;32mIn [1883]\u001B[0m, in \u001B[0;36mSeasonRoundEncoder.__call__\u001B[1;34m(self, sample)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, sample: pd\u001B[38;5;241m.\u001B[39mDataFrame) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor:\n\u001B[1;32m----> 8\u001B[0m     season_encoding \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([[el] \u001B[38;5;28;01mfor\u001B[39;00m el \u001B[38;5;129;01min\u001B[39;00m \u001B[43msample\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mseason\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmapping)\u001B[38;5;241m.\u001B[39mtolist()], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint32)\n\u001B[0;32m      9\u001B[0m     round_encoding \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([[el] \u001B[38;5;28;01mfor\u001B[39;00m el \u001B[38;5;129;01min\u001B[39;00m sample[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mround\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint32)\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat([season_encoding, round_encoding], \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mD:\\Windows\\Programmi\\miniconda3\\envs\\footballprediction\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32mD:\\Windows\\Programmi\\miniconda3\\envs\\footballprediction\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3623\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3624\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3625\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3626\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3627\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3628\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'season'"
     ]
    }
   ],
   "source": [
    "train_model(model=model, dataloader=train_dataloader, optimizer=optimizer, loss_fn=cross_entropy_loss_fn, num_epochs=num_epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Missing data\n",
    "- We don't have data about new players that come to play in _Serie A_ during the course of the seasons. The model has to learn from zero context how important their contribution is for the outcome of the matches. If we were to considered multiple leagues, we could keep track of player transfers and maintain the history.\n",
    "- We don't have data about cup matches played during the course of the seasons, like _Champions League_, _Europa League_ and _Coppa Italia_. Since they are very prestigious competitions and matches are usually very competitive, teams put a lot of effort in them and therefore can then perform worse in the championship.\n",
    "- We don't have any type of player performance metric like who scored a goal, who was the assist man, red or yellow cards, goalkeeper's saves etc. so the model could face some difficulties in learning which player is important for the team."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}